import json
import glob
import os
import argparse

def display_stats(all_f_and_v):
    print("DATASET FEATURES AND FEATURE-VALUE STATS:")
    features_with_no_values = []
    counter_features = 0 
    for feature in all_f_and_v:
        if len(all_f_and_v[feature]) == 0:
            features_with_no_values.append(feature)
        else:
            print(feature + ": " + str(len(all_f_and_v[feature])))
            counter_features += 1
    print("++++++++++++++++++++++++")
    print("features in dataset with no values: ")
    for f in features_with_no_values:
        print(f)

    print("=========================")
    print("total features: " + str(len(all_f_and_v.items())))
    print("total features with non-zero values: " + str(counter_features))
    print("total features with zero values (unusable): " + str(len(features_with_no_values)))
    # pipe output into: | sort -k2n

def enumerate_all_features(path_to_dataset):
    all_features_in_dataset = {}

    # recursively open all files
    for filename in glob.iglob(path_to_dataset + '/**/*.json', recursive=True):
        with open(filename) as data_file:
            data = json.load(data_file)

            # include only Zeus, Crypto, Locker, and APT1 
            # and ignore other malware families
            lbl = data["properties"]["label"]
            if not lbl == "APT1" and \
               not lbl == "Crypto" and \
               not lbl == "Locker" and \
               not lbl == "Zeus":
                print("SKIPPING: " + filename)
                continue
             
            print("PROCESSING: " + filename)

            # get all properties for this file
            properties = sorted((data["properties"]).keys())

            # add feature and values to dictionary
            for feature in properties:
                if not feature in all_features_in_dataset:
                    # create empty list as value if first time seeing feature
                    all_features_in_dataset[feature] =[] 
                    feature_values_str  = data["properties"][feature]
                    feature_values_list = [x for x in feature_values_str.split()]
                    for f_value in feature_values_list:
                        all_features_in_dataset[feature].append(f_value)
                else:
                    feature_values_str  = data["properties"][feature]
                    feature_values_list = [x for x in feature_values_str.split()]
                    for f_value in feature_values_list:
                        all_features_in_dataset[feature].append(f_value)

    # post procesing to remove duplicates 
    # convert to set (keep unique) and then back to list (sorted)
    for k, v in all_features_in_dataset.items():
        all_features_in_dataset[k] = sorted(list(set(v)))
        
    print("//////// COMPLETE //////////\n")
    return all_features_in_dataset

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("path_to_tng_data", help="full path to malware training data set")
    parser.add_argument("output_file", help="name of output json file to contain all features and values in dataset")
    args = parser.parse_args()

    all_features = enumerate_all_features(args.path_to_tng_data)

    # display stats on dataset to include 
    display_stats(all_features)

    # write out all features and values in dataset to file
    with open(args.output_file, 'w') as outfile:
        outfile.write(json.dumps(all_features, sort_keys=True, indent=4))

